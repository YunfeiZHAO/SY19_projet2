test<-car[1,]
test<-(matrix(test, 100, 100, byrow=TRUE))
image(test)
test<-car[1,]
test<-matrix(test, 100, 100, byrow=TRUE)
image(test)
test<-car[1,]
test<-t(matrix(test, 100, 100))
image(test)
test<-matrix(test, 100, 100)
image(test)
test<-car[1,]
test<-matrix(test, 100, 100)
image(test)
View(car)
test<-car[1,]
test<-matrix(test, 100, 100)
image(test)
test<-car[1,]
test<-t(matrix(test, 100, 100))
image(test)
test<-t(matrix(test, 100, 100))
image(test)
a<-matrix(2,2)
a
a<-matrix(c(1,2,3,4),2,2)
a
# data splitting
n <- nrow(car) + nrow(cat) + nrow(flower)
n
ntrain <- 2*n/3
idx.train = sample(n, ntrain)
ntrain <- length(idx.train)
ntest <- n - ntrain
array(10)
a<-array(10)
a
y <- rep(1, nrow(car))
y
y1 <- rep(1, nrow(car))
y1 <- rep(1, nrow(car))
y2 <- rep(2, nrow(cat))
y3 <- rep(3, nrow(flower))
y <- cbind(y1, y2, y3)
y <- rbind(y1, y2, y3)
y <- cbind(y1, y2, y3)
y1
dim(y1)
y <- y1 + y2+ y3
y <- c(y1, y2, y3)
y
y(1000)
y[1000]
y[1500]
ytrain <- y[idx.trainImg]
# data splitting
n <- nrow(car) + nrow(cat) + nrow(flower)
y1 <- rep(1, nrow(car))
y2 <- rep(2, nrow(cat))
y3 <- rep(3, nrow(flower))
y <- c(y1, y2, y3)
ntrainImg <- 2*n/3
idx.trainImg = sample(n, ntrain)
ntrainImg <- length(idx.trainImg)
ntestImg <- n - ntrainImg
ytrainImg <- y[idx.trainImg]
ytestImg <- y[-idx.trainImg]
data.image<- rbind(car, cat, flower)
view(data.image)
View(data.image)
xtrainImg <- data.image[idx.trainImg]
xtestImg <- data.image[-idx.trainImg]
dim(xtrainImg)
View(xtrainImg)
View(data.image)
xtrainImg <- data.image[idx.trainImg,]
xtestImg <- data.image[-idx.trainImg,]
dim(xtrainImg)
length(ytrainImg)
# data splitting
n <- nrow(car) + nrow(cat) + nrow(flower)
y1 <- rep(1, nrow(car))
y2 <- rep(2, nrow(cat))
y3 <- rep(3, nrow(flower))
y <- c(y1, y2, y3)
ntrainImg <- 2*n/3
idx.trainImg = sample(n, ntrain)
ntrainImg <- length(idx.trainImg)
ntestImg <- n - ntrainImg
ytrainImg <- y[idx.trainImg]
ytestImg <- y[-idx.trainImg]
data.image<- rbind(car, cat, flower)
xtrainImg <- data.image[idx.trainImg,]
xtestImg <- data.image[-idx.trainImg,]
#kera
model <- keras_model_sequential()
y
y
#kera
model <- keras_model_sequential()
##############################3 Images naturelles###############################
library(keras)
library(imager)
#kera
model <- keras_model_sequential()
conda activate r-reticulate
#kera
model <- keras_model_sequential()
# data splitting
n <- nrow(car) + nrow(cat) + nrow(flower)
y1 <- rep(1, nrow(car))
y2 <- rep(2, nrow(cat))
y3 <- rep(3, nrow(flower))
y <- c(y1, y2, y3)
ntrainImg <- 2*n/3
idx.trainImg = sample(n, ntrain)
ntrainImg <- length(idx.trainImg)
ntestImg <- n - ntrainImg
ytrainImg <- y[idx.trainImg]
ytestImg <- y[-idx.trainImg]
data.image<- rbind(car, cat, flower)
xtrainImg <- data.image[idx.trainImg,]
xtestImg <- data.image[-idx.trainImg,]
#kera
model <- keras_model_sequential()
##############################3 Images naturelles###############################
library(keras)
library(imager)
#kera
model <- keras_model_sequential()
model %>% layer_dense(units = 30, activation = 'relu', input_shape = 10000) %>%
layer_dense(units = 20, activation = 'relu',name="cache1") %>%
layer_dense(units = 5, activation = 'relu',name="cache2") %>%
layer_dense(units = 3, activation = 'linear',name="sortie")
#kera
model <- keras_model_sequential()
car <- read.images("./data/images_train/car/")
cat <- read.images("./data/images_train/cat/")
View(data.image)
View(data.image)
# Chargement de l’environnement
load("env.Rdata")
classifieur_astronomie <- function(dataset) {
library(nnet)
# Chargement de l’environnement
load("env.Rdata")
# Mon algorithme qui renvoie les prédictions sur le jeu de données
# ‘dataset‘ fourni en argument. # ...
class <- dataset$class
# remove constant
X <- subset(dataset, select = -c(class, objid, rerun))
#scaling
X <- scale(X)
# PCA
astronomy<-data.frame(X%*%pca.rotation)
#astronomy<-cbind(astronomy, class)
View(astronomy)
#astronomy$class <- as.factor(astronomy$class)
predictions<-predict(fit.MLR.norm, newdata=astronomy)
return(predictions)
}
setwd("/Users/yunfei/Desktop/GI04/SY19/tp10/SY19_projet2/")
data <- read.csv("./data/astronomy_train.csv",sep=",",header=TRUE)
n <- nrow(data)
ntest <- 2000
idx <- sample(n, ntest)
prediction <- classifieur_astronomie(data[idx,])
load("env.Rdata")
save(fit.MLR.norm, file = "env.RData")
load("classifieur_astronomie.Rdata")
load("classifier_astronomie.RData")
save(fit.MLR.norm, file = "env.RData")
load("env.Rdata")
save(pca.rotation, file = "env.RData")
pca.rotation <- pca$rotation
load("classifier_astronomie.RData")
pca.rotation <- pca$rotation
save(fit.MLR.norm, file = "env.RData")
save(pca.rotation, file = "env.RData")
load("env.Rdata")
load("classifier_astronomie.RData")
pca.rotation <- pca$rotation
save(c(fit.MLR.norm, pca.rotation), file = "env.RData")
save(fit.MLR.norm, pca.rotation, file = "env.RData")
load("env.Rdata")
classifieur_astronomie <- function(dataset) {
library(nnet)
# Chargement de l’environnement
load("env.Rdata")
# Mon algorithme qui renvoie les prédictions sur le jeu de données
# ‘dataset‘ fourni en argument. # ...
class <- dataset$class
# remove constant
X <- subset(dataset, select = -c(class, objid, rerun))
#scaling
X <- scale(X)
# PCA
astronomy<-data.frame(X%*%pca.rotation)
#astronomy<-cbind(astronomy, class)
View(astronomy)
#astronomy$class <- as.factor(astronomy$class)
predictions<-predict(fit.MLR.norm, newdata=astronomy)
return(predictions)
}
setwd("/Users/yunfei/Desktop/GI04/SY19/tp10/SY19_projet2/")
data <- read.csv("./data/astronomy_train.csv",sep=",",header=TRUE)
n <- nrow(data)
ntest <- 2000
idx <- sample(n, ntest)
prediction <- classifieur_astronomie(data[idx,])
matrix.conf <- table(prediction, data[idx, "class"])
matrix.conf
err <- 1 - sum(diag(matrix.conf))/ntest
err
load("classifier_astronomie.RData")
#----------------------------
# Multinomial Logistic Regression
#----------------------------
###############final################
fit.MLR.final <- multinom(class ~ ., data = astronomy.normalised)
summary(fit.MLR.final)
pred.MLR.final <- predict(fit.MLR.final, newdata=astronomy.normalised)
matrix.conf.MLR.final <- table(pred.MLR.final, astronomy.normalised[, "class"])
matrix.conf.MLR.final
err.MLR.final <- 1 - sum(diag(matrix.conf.MLR.final))/n
err.MLR.final
##CARET choose variable
getwd()
setwd("/Users/yunfei/Desktop/GI04/SY19/tp10/SY19_projet2/")
# read data
astronomy <- read.csv("./data/astronomy_train.csv",sep=",",header=TRUE)
head(astronomy)
# data splitting
n <- nrow(astronomy)
ntrain <- 2*n/3
idx.train = sample(n, ntrain)
ntrain <- length(idx.train)
ntest <- n - ntrain
# Nested cross validation
n<-nrow(astronomy)
n_folds<-12
# data cleaning
## remove variable with constant value
class <- astronomy$class
astronomy <- subset(astronomy, select = -c(class))
s<-apply(astronomy, 2, sd)
ii<-which(s>0)
iix <- which(s<=0)
astronomy<-astronomy[, ii]
astronomy<-cbind(astronomy, class)
astronomy$class <- as.factor(astronomy$class)
# visualisation of class
#View(astronomy)
hist(as.numeric(astronomy$class))
#Correlation check
correlations <- cor(subset(astronomy, select = -c(class)),method="pearson")
corrplot(correlations, number.cex = .9, method = "circle", type = "full", tl.cex=1,tl.col = "black")
## data normalisation
scaled.X <- scale(subset(astronomy, select = -c(class)))
pca<-prcomp(scaled.X)
#plot(cumsum(lambda)/sum(lambda), xlab="q")
# take fisrt 10 variable
pca.X <- data.frame(pca$x[,1:12])
astronomy.normalised<-cbind(pca.X, class)
astronomy.normalised$class <- as.factor(class)
correlations.pca <- cor(subset(astronomy.normalised, select = -c(class)),method="pearson")
corrplot(correlations.pca, number.cex = .9, method = "circle", type = "full", tl.cex=1,tl.col = "black")
#----------------------------
# KNN
#----------------------------
fit.KNN <- kknn(class~., astronomy[idx.train,], astronomy[-idx.train,], distance = 1, kernel = "triangular")
pred.KNN <- fit.KNN$fitted.values
matrix.conf.KNN<-table(pred.KNN, astronomy[-idx.train, "class"])
matrix.conf.KNN
err.KNN <- 1 - sum(diag(matrix.conf.KNN))/ntest
err.KNN
#0.1019796
#----------------------------
# LDA
#----------------------------
##Model building##
fit.LDA<- lda(class~.,data=astronomy.normalised[idx.train,])
pred.LDA<-predict(fit.LDA, newdata=astronomy.normalised[-idx.train,])
matrix.conf.LDA<-table(pred.LDA$class, astronomy[-idx.train, "class"])
matrix.conf.LDA
err.LDA <- 1 - sum(diag(matrix.conf.LDA))/ntest
err.LDA
roc_LDA <- multiclass.roc(astronomy.normalised[-idx.train,]$class, pred.LDA$posterior, plot=TRUE)
#----------------------------
# QDA
#----------------------------
fit.QDA<- qda(class~.,data=astronomy.normalised[idx.train,])
library(kknn)
library(rpart)
library(pROC)
library(MASS)
library(corrplot)
library(nnet)
##CARET choose variable
getwd()
setwd("/Users/yunfei/Desktop/GI04/SY19/tp10/SY19_projet2/")
# read data
astronomy <- read.csv("./data/astronomy_train.csv",sep=",",header=TRUE)
head(astronomy)
# data splitting
n <- nrow(astronomy)
ntrain <- 2*n/3
idx.train = sample(n, ntrain)
ntrain <- length(idx.train)
ntest <- n - ntrain
# Nested cross validation
n<-nrow(astronomy)
n_folds<-12
# data cleaning
## remove variable with constant value
class <- astronomy$class
astronomy <- subset(astronomy, select = -c(class))
s<-apply(astronomy, 2, sd)
ii<-which(s>0)
iix <- which(s<=0)
astronomy<-astronomy[, ii]
astronomy<-cbind(astronomy, class)
astronomy$class <- as.factor(astronomy$class)
# visualisation of class
#View(astronomy)
hist(as.numeric(astronomy$class))
#Correlation check
correlations <- cor(subset(astronomy, select = -c(class)),method="pearson")
corrplot(correlations, number.cex = .9, method = "circle", type = "full", tl.cex=1,tl.col = "black")
## data normalisation
scaled.X <- scale(subset(astronomy, select = -c(class)))
pca<-prcomp(scaled.X)
#plot(cumsum(lambda)/sum(lambda), xlab="q")
# take fisrt 10 variable
pca.X <- data.frame(pca$x[,1:12])
astronomy.normalised<-cbind(pca.X, class)
astronomy.normalised$class <- as.factor(class)
correlations.pca <- cor(subset(astronomy.normalised, select = -c(class)),method="pearson")
corrplot(correlations.pca, number.cex = .9, method = "circle", type = "full", tl.cex=1,tl.col = "black")
#----------------------------
# KNN
#----------------------------
fit.KNN <- kknn(class~., astronomy[idx.train,], astronomy[-idx.train,], distance = 1, kernel = "triangular")
pred.KNN <- fit.KNN$fitted.values
matrix.conf.KNN<-table(pred.KNN, astronomy[-idx.train, "class"])
matrix.conf.KNN
err.KNN <- 1 - sum(diag(matrix.conf.KNN))/ntest
err.KNN
#0.1019796
#----------------------------
# LDA
#----------------------------
##Model building##
fit.LDA<- lda(class~.,data=astronomy.normalised[idx.train,])
pred.LDA<-predict(fit.LDA, newdata=astronomy.normalised[-idx.train,])
matrix.conf.LDA<-table(pred.LDA$class, astronomy[-idx.train, "class"])
matrix.conf.LDA
err.LDA <- 1 - sum(diag(matrix.conf.LDA))/ntest
err.LDA
roc_LDA <- multiclass.roc(astronomy.normalised[-idx.train,]$class, pred.LDA$posterior, plot=TRUE)
#----------------------------
# QDA
#----------------------------
fit.QDA<- qda(class~.,data=astronomy.normalised[idx.train,])
pred.QDA<-predict(fit.QDA, newdata=astronomy.normalised[-idx.train,])
matrix.conf.QDA <-table(pred.QDA$class, astronomy[-idx.train, "class"])
matrix.conf.QDA
1-sum(diag(matrix.conf.QDA))/ntest
fit.QDA<- qda(class~dec + u + g + run + camcol + field + redshift + fiberid, data=astronomy[idx.train,])
pred.QDA<-predict(fit.QDA, newdata=astronomy[-idx.train,])
matrix.conf.QDA <-table(pred.QDA$class, astronomy[-idx.train, "class"])
matrix.conf.QDA
1-sum(diag(matrix.conf.QDA))/ntest
#----------------------------
# naive Bayes
#----------------------------
library(naivebayes)
fit.naive<- naive_bayes(class~.,astronomy.normalised[idx.train,])
pred.naive<-predict(fit.naive, newdata=astronomy.normalised[-idx.train,])
pred.naive <- as.factor(pred.naive)
matrix.conf.naive<-table(pred.naive, astronomy.normalised[-idx.train, "class"])
matrix.conf.naive
1-sum(diag(matrix.conf.naive))/ntest
#----------------------------
# Multinomial Logistic Regression
#----------------------------
###############final################
fit.MLR.final <- multinom(class ~ ., data = astronomy.normalised)
summary(fit.MLR.final)
pred.MLR.final <- predict(fit.MLR.final, newdata=astronomy.normalised)
matrix.conf.MLR.final <- table(pred.MLR.final, astronomy.normalised[, "class"])
matrix.conf.MLR.final
err.MLR.final <- 1 - sum(diag(matrix.conf.MLR.final))/n
err.MLR.final
library(kknn)
library(rpart)
library(pROC)
library(MASS)
library(corrplot)
library(nnet)
##CARET choose variable
getwd()
setwd("/Users/yunfei/Desktop/GI04/SY19/tp10/SY19_projet2/")
# read data
astronomy <- read.csv("./data/astronomy_train.csv",sep=",",header=TRUE)
head(astronomy)
# data splitting
n <- nrow(astronomy)
ntrain <- 2*n/3
idx.train = sample(n, ntrain)
ntrain <- length(idx.train)
ntest <- n - ntrain
# Nested cross validation
n<-nrow(astronomy)
n_folds<-12
# data cleaning
## remove variable with constant value
class <- astronomy$class
astronomy <- subset(astronomy, select = -c(class))
s<-apply(astronomy, 2, sd)
ii<-which(s>0)
iix <- which(s<=0)
astronomy<-astronomy[, ii]
astronomy<-cbind(astronomy, class)
astronomy$class <- as.factor(astronomy$class)
# visualisation of class
#View(astronomy)
hist(as.numeric(astronomy$class))
#Correlation check
correlations <- cor(subset(astronomy, select = -c(class)),method="pearson")
corrplot(correlations, number.cex = .9, method = "circle", type = "full", tl.cex=1,tl.col = "black")
## data normalisation
scaled.X <- scale(subset(astronomy, select = -c(class)))
pca<-prcomp(scaled.X)
#plot(cumsum(lambda)/sum(lambda), xlab="q")
# take fisrt 10 variable
pca.X <- data.frame(pca$x[,1:12])
astronomy.normalised<-cbind(pca.X, class)
astronomy.normalised$class <- as.factor(class)
correlations.pca <- cor(subset(astronomy.normalised, select = -c(class)),method="pearson")
corrplot(correlations.pca, number.cex = .9, method = "circle", type = "full", tl.cex=1,tl.col = "black")
#----------------------------
# KNN
#----------------------------
fit.KNN <- kknn(class~., astronomy[idx.train,], astronomy[-idx.train,], distance = 1, kernel = "triangular")
pred.KNN <- fit.KNN$fitted.values
matrix.conf.KNN<-table(pred.KNN, astronomy[-idx.train, "class"])
matrix.conf.KNN
err.KNN <- 1 - sum(diag(matrix.conf.KNN))/ntest
err.KNN
#0.1019796
#----------------------------
# LDA
#----------------------------
##Model building##
fit.LDA<- lda(class~.,data=astronomy.normalised[idx.train,])
pred.LDA<-predict(fit.LDA, newdata=astronomy.normalised[-idx.train,])
matrix.conf.LDA<-table(pred.LDA$class, astronomy[-idx.train, "class"])
matrix.conf.LDA
err.LDA <- 1 - sum(diag(matrix.conf.LDA))/ntest
err.LDA
roc_LDA <- multiclass.roc(astronomy.normalised[-idx.train,]$class, pred.LDA$posterior, plot=TRUE)
#----------------------------
# QDA
#----------------------------
fit.QDA<- qda(class~.,data=astronomy.normalised[idx.train,])
pred.QDA<-predict(fit.QDA, newdata=astronomy.normalised[-idx.train,])
matrix.conf.QDA <-table(pred.QDA$class, astronomy[-idx.train, "class"])
matrix.conf.QDA
1-sum(diag(matrix.conf.QDA))/ntest
fit.QDA<- qda(class~dec + u + g + run + camcol + field + redshift + fiberid, data=astronomy[idx.train,])
pred.QDA<-predict(fit.QDA, newdata=astronomy[-idx.train,])
matrix.conf.QDA <-table(pred.QDA$class, astronomy[-idx.train, "class"])
matrix.conf.QDA
1-sum(diag(matrix.conf.QDA))/ntest
#----------------------------
# naive Bayes
#----------------------------
library(naivebayes)
fit.naive<- naive_bayes(class~.,astronomy.normalised[idx.train,])
pred.naive<-predict(fit.naive, newdata=astronomy.normalised[-idx.train,])
pred.naive <- as.factor(pred.naive)
matrix.conf.naive<-table(pred.naive, astronomy.normalised[-idx.train, "class"])
matrix.conf.naive
1-sum(diag(matrix.conf.naive))/ntest
#----------------------------
# Multinomial Logistic Regression
#----------------------------
###############final################
fit.MLR.final <- multinom(class ~ ., data = astronomy.normalised)
summary(fit.MLR.final)
pred.MLR.final <- predict(fit.MLR.final, newdata=astronomy.normalised)
matrix.conf.MLR.final <- table(pred.MLR.final, astronomy.normalised[, "class"])
matrix.conf.MLR.final
err.MLR.final <- 1 - sum(diag(matrix.conf.MLR.final))/n
err.MLR.final
pca.rotation <- pca$rotation
save(pred.MLR.final, pca.rotation, file = "env.RData")
fit.MLR.norm <- multinom(class ~ ., data = astronomy.normalised[idx.train,])
summary(fit.MLR.norm)
pred.MLR.norm <- predict(fit.MLR.norm, newdata=astronomy.normalised[-idx.train,])
matrix.conf.MLR.norm <- table(pred.MLR.norm, astronomy.normalised[-idx.train, "class"])
matrix.conf.MLR.norm
err.MLR.norm <- 1 - sum(diag(matrix.conf.MLR.norm))/ntest
err.MLR.norm
load("classifier_astronomie.RData")
load("classifier_astronomie.RData")
pred.MLR.norm <- predict(fit.MLR.norm, newdata=astronomy.normalised[-idx.train,])
matrix.conf.MLR.norm <- table(pred.MLR.norm, astronomy.normalised[-idx.train, "class"])
matrix.conf.MLR.norm
err.MLR.norm <- 1 - sum(diag(matrix.conf.MLR.norm))/ntest
err.MLR.norm
